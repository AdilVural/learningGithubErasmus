{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3cfbe7",
   "metadata": {},
   "source": [
    "# Opgave 5 — Voorspellen van *Apps* (Deel 2: 5a–5l)\n",
    "\n",
    "**Doel:** Bouw en valideer een regressiemodel dat het aantal aanmeldingen **Apps** voorspelt op basis van factoren die *vooraf* bekend zijn. Gebruik geen `Accept` of `Enroll`.\n",
    "\n",
    "**Bronnen (slides & boek):**\n",
    "- **Lecture 1–5 hand-outs** (kern: L2 distributies & normaliteit, L3 toetsen & splitsen, L4 OLS, L5 diagnostiek, selectie & validatie)\n",
    "- **Practical Statistics for Data Scientists (PSDS)** – hoofdstukken over regressie, validatie en diagnostiek\n",
    "\n",
    "> Deze notebook volgt de structuur 5a t/m 5l. Bij elke stap staat een korte verwijzing naar relevante slides/boek.\n",
    "> **Datum gegenereerd:** 2025-10-09 19:47 (regenerated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154291b",
   "metadata": {},
   "source": [
    "\n",
    "## 5a — Normaliteit van `Apps`\n",
    "**Bronnen:** Lecture 2 (normality & CLT), Lecture 3 (normality testing), *PSDS* p. 49–52\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv(\"college_statistics.csv\")  # Plaats dit bestand naast het notebook\n",
    "plt.figure(); plt.hist(df[\"Apps\"].dropna(), bins=30)\n",
    "plt.title(\"Distribution of Apps\"); plt.xlabel(\"Apps\"); plt.ylabel(\"Frequency\"); plt.show()\n",
    "plt.figure(); stats.probplot(df[\"Apps\"].dropna(), dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot of Apps\"); plt.show()\n",
    "stat, p = stats.shapiro(df[\"Apps\"].dropna())\n",
    "print(f\"Shapiro-Wilk statistic = {stat:.4f}, p-value = {p:.4f}\")\n",
    "df[\"log_Apps\"] = np.log(df[\"Apps\"])\n",
    "print(\"Kolommen:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a629138",
   "metadata": {},
   "source": [
    "## 5b — Estimation/Test-split (600/overig)\n",
    "**Bron:** Lecture 3 (estimation & test samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860003ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed(1234)\n",
    "train, test = train_test_split(df, train_size=600, random_state=1234)\n",
    "print(\"Train shape:\", train.shape, \"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b797c4",
   "metadata": {},
   "source": [
    "## 5c — OLS-modelbouw (log_Apps)\n",
    "**Bronnen:** Lecture 4 (multiple linear regression), *PSDS* p. 100–107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "base_formula = \"log_Apps ~ SAT + Top10perc + Room.Board + Expend + Grad.Rate\"\n",
    "model_base = smf.ols(base_formula, data=train).fit()\n",
    "print(model_base.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beab24a",
   "metadata": {},
   "source": [
    "## 5d — RMSE op log-schaal\n",
    "**Bronnen:** Lecture 5 (model fit), *PSDS* p. 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76341851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "y_pred_log = model_base.predict(test)\n",
    "rmse_log = float(np.sqrt(mean_squared_error(test[\"log_Apps\"], y_pred_log)))\n",
    "print(f\"Test RMSE (log-scale) = {rmse_log:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e52af2",
   "metadata": {},
   "source": [
    "## 5e — Diagnostiek (residuen, BP, DW, VIF)\n",
    "**Bronnen:** Lecture 5 (diagnostics), *PSDS* p. 122–130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import patsy\n",
    "\n",
    "resid = model_base.resid\n",
    "plt.figure(); sm.qqplot(resid, line=\"45\"); plt.title(\"QQ Plot of Residuals (Base Model)\"); plt.show()\n",
    "\n",
    "bp = sm.stats.diagnostic.het_breuschpagan(resid, model_base.model.exog)\n",
    "print(f\"Breusch–Pagan p-value = {float(bp[1]):.4f}\")\n",
    "dw = sm.stats.stattools.durbin_watson(resid)\n",
    "print(f\"Durbin–Watson = {dw:.2f}\")\n",
    "\n",
    "y_mat, X_mat = patsy.dmatrices(base_formula, train, return_type=\"dataframe\")\n",
    "vif_table = pd.DataFrame({\n",
    "    \"variable\": X_mat.columns,\n",
    "    \"VIF\": [variance_inflation_factor(X_mat.values, i) for i in range(X_mat.shape[1])]\n",
    "}).sort_values(\"VIF\", ascending=False)\n",
    "print(vif_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f8e2b",
   "metadata": {},
   "source": [
    "## 5f — Modelselectie (AIC, all-subsets)\n",
    "**Bronnen:** Lecture 5 (AIC), *PSDS* p. 134–136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e284ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "candidate_vars = [\"SAT\", \"Top10perc\", \"Room.Board\", \"Expend\", \"Grad.Rate\"]\n",
    "def best_aic_subset(y, Xvars, data):\n",
    "    best = {\"aic\": float(\"inf\"), \"model\": None, \"vars\": None, \"formula\": None}\n",
    "    for k in range(1, len(Xvars)+1):\n",
    "        for combo in itertools.combinations(Xvars, k):\n",
    "            f = f\"{y} ~ \" + \" + \".join(combo)\n",
    "            m = smf.ols(f, data=data).fit()\n",
    "            if m.aic < best[\"aic\"]:\n",
    "                best = {\"aic\": float(m.aic), \"model\": m, \"vars\": combo, \"formula\": f}\n",
    "    return best\n",
    "best_sub = best_aic_subset(\"log_Apps\", candidate_vars, train)\n",
    "print(\"Best subset:\", best_sub[\"vars\"], \"| AIC:\", round(best_sub[\"aic\"], 2))\n",
    "print(best_sub[\"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f5a49",
   "metadata": {},
   "source": [
    "## 5g — Feature engineering (transformaties/interacties)\n",
    "**Bronnen:** Lecture 4 (functionele vormen), *PSDS* p. 111–113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f80938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"log_Expend\"] = np.log(train[\"Expend\"]); test[\"log_Expend\"] = np.log(test[\"Expend\"])\n",
    "fe_formula = \"log_Apps ~ SAT + I(SAT**2) + Top10perc + Room.Board + log_Expend + Grad.Rate + SAT:Top10perc\"\n",
    "model_fe = smf.ols(fe_formula, data=train).fit()\n",
    "print(\"FE AIC:\", round(model_fe.aic, 2)); print(model_fe.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f402778",
   "metadata": {},
   "source": [
    "## 5h — K-fold cross-validation (5-fold RMSE)\n",
    "**Bronnen:** Lecture 5 (validation techniques), *PSDS* p. 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def cv_rmse(formula, data, k=5, random_state=1234):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    rmses = []\n",
    "    for tr_idx, va_idx in kf.split(data):\n",
    "        tr = data.iloc[tr_idx]; va = data.iloc[va_idx]\n",
    "        m = smf.ols(formula, data=tr).fit()\n",
    "        pred = m.predict(va)\n",
    "        rmses.append(float(np.sqrt(mean_squared_error(va[\"log_Apps\"], pred))))\n",
    "    return float(np.mean(rmses)), float(np.std(rmses))\n",
    "\n",
    "sub_formula = best_sub[\"formula\"]\n",
    "cv_sub = cv_rmse(sub_formula, train)\n",
    "cv_fe  = cv_rmse(fe_formula,   train)\n",
    "print(\"CV RMSE (subset):\", cv_sub)\n",
    "print(\"CV RMSE (FE):    \", cv_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a57eae",
   "metadata": {},
   "source": [
    "## 5i — Robuuste standaardfouten (HC3)\n",
    "**Bronnen:** Lecture 5 (robust inference), *PSDS* p. 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d12066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefer_formula = fe_formula if cv_fe[0] <= cv_sub[0] else sub_formula\n",
    "model_pref = smf.ols(prefer_formula, data=train).fit()\n",
    "model_pref_HC3 = model_pref.get_robustcov_results(cov_type=\"HC3\")\n",
    "print(\"Prefered formula:\", prefer_formula)\n",
    "print(\"AIC (non-robust):\", round(model_pref.aic, 2))\n",
    "print(model_pref_HC3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e14202",
   "metadata": {},
   "source": [
    "## 5j — Outliers, leverage & invloed (Cook’s D)\n",
    "**Bronnen:** Lecture 5 (influence measures), *PSDS* p. 128–130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afced599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "infl = OLSInfluence(model_pref)\n",
    "cooks_d = infl.cooks_distance[0]; lev = infl.hat_matrix_diag\n",
    "n = len(train); p = model_pref.df_model + 1; thr = 4 / (n - p)\n",
    "idx = np.where(cooks_d > thr)[0]\n",
    "print(f\"Aantal high-influence punten: {len(idx)}; drempel ~ {thr:.5f}\")\n",
    "if len(idx) > 0:\n",
    "    train_sens = train.drop(train.index[idx])\n",
    "    model_sens = smf.ols(prefer_formula, data=train_sens).fit()\n",
    "    import pandas as pd\n",
    "    comp = pd.DataFrame({\"orig\": model_pref.params, \"sens\": model_sens.params})\n",
    "    print(comp.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a1a03",
   "metadata": {},
   "source": [
    "## 5k — Multicollineariteit (VIF & centreren)\n",
    "**Bronnen:** Lecture 5 (multicollinearity), *PSDS* p. 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y0, X0 = patsy.dmatrices(prefer_formula, train, return_type=\"dataframe\")\n",
    "vif0 = pd.DataFrame({\"variable\": X0.columns,\n",
    "                     \"VIF\": [variance_inflation_factor(X0.values, i) for i in range(X0.shape[1])]}\n",
    "                   ).sort_values(\"VIF\", ascending=False)\n",
    "print(\"VIF voor centreren:\"); print(vif0.head(10))\n",
    "\n",
    "cols_to_center = []\n",
    "for c in [\"SAT\", \"Top10perc\", \"Room.Board\", \"log_Expend\", \"Grad.Rate\"]:\n",
    "    if c in train.columns:\n",
    "        cols_to_center.append(c)\n",
    "        train[c + \"_c\"] = train[c] - train[c].mean()\n",
    "        test[c + \"_c\"]  = test[c]  - train[c].mean()\n",
    "\n",
    "prefer_formula_c = prefer_formula\n",
    "for c in cols_to_center: prefer_formula_c = prefer_formula_c.replace(c, c + \"_c\")\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "model_pref_c = smf.ols(prefer_formula_c, data=train).fit()\n",
    "\n",
    "y1, X1 = patsy.dmatrices(prefer_formula_c, train, return_type=\"dataframe\")\n",
    "vif1 = pd.DataFrame({\"variable\": X1.columns,\n",
    "                     \"VIF\": [variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])]}\n",
    "                   ).sort_values(\"VIF\", ascending=False)\n",
    "print(\"VIF na centreren:\"); print(vif1.head(10))\n",
    "print(model_pref_c.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742dbb60",
   "metadata": {},
   "source": [
    "## 5l — Eindmodel, terug naar **Apps** (Duan smearing) & eind-RMSE\n",
    "**Bronnen:** Lecture 5 (prediction & assessment), *PSDS* p. 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "final_model = model_pref_c  # kies je eindmodel hier expliciet\n",
    "\n",
    "train_pred_log = final_model.predict(train)\n",
    "smearing = float(np.mean(np.exp(train[\"log_Apps\"] - train_pred_log)))\n",
    "\n",
    "test_pred_log = final_model.predict(test)\n",
    "test_pred_apps = np.exp(test_pred_log) * smearing\n",
    "\n",
    "rmse_apps = float(np.sqrt(mean_squared_error(test[\"Apps\"], test_pred_apps)))\n",
    "print(f\"Final test RMSE (Apps-scale) = {rmse_apps:,.2f}\")\n",
    "\n",
    "baseline_rmse = float(np.sqrt(mean_squared_error(test[\"Apps\"], np.repeat(train['Apps'].mean(), len(test)))))\n",
    "print(f\"Baseline RMSE (predict mean) = {baseline_rmse:,.2f}\")\n",
    "print(f\"Verbetering t.o.v. baseline: {100*(1 - rmse_apps/baseline_rmse):.1f}%\")\n",
    "\n",
    "def predict_apps(new_df, train_ref=train, model=final_model, smear=smearing):\n",
    "    import numpy as np, pandas as pd\n",
    "    new_df = new_df.copy()\n",
    "    if \"Expend\" in new_df and \"log_Expend\" not in new_df:\n",
    "        new_df[\"log_Expend\"] = np.log(new_df[\"Expend\"])\n",
    "    for c in [\"SAT\", \"Top10perc\", \"Room.Board\", \"log_Expend\", \"Grad.Rate\"]:\n",
    "        if c in new_df and (c + \"_c\") in train_ref.columns:\n",
    "            new_df[c + \"_c\"] = new_df[c] - train_ref[c].mean()\n",
    "    log_hat = model.predict(new_df)\n",
    "    return np.exp(log_hat) * smear\n",
    "\n",
    "# Voorbeeld:\n",
    "# new = pd.DataFrame({\"SAT\":[1200], \"Top10perc\":[20], \"Room.Board\":[10000], \"Expend\":[8000], \"Grad.Rate\":[70]})\n",
    "# print(predict_apps(new))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
